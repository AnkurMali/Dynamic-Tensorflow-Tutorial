{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <span style=\"color:green\"> 2 Layer Stacked LSTM ON 8*8 MNIST DATASET TO PREDICT TEN CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "### <span style=\"color:blue\">Its a dynamic sequence and batch Two layer stacked LSTM . This is created with tensorflow scan and map higher ops!!!! \n",
    "###  <span style=\"color:blue\">This is a base Two layer stacked LSTM which can be used to create stacked Neural Stack Machine, Neural Turing Machine and  RNN-EM and so on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jli183/tensorflow/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STACKED LSTM class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LSTM_cell(object):\n",
    "\n",
    "    \"\"\"\n",
    "    LSTM cell object which takes 3 arguments for initialization.\n",
    "    input_size = Input Vector size\n",
    "    hidden_layer_size = Hidden layer size\n",
    "    target_size = Output vector size\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_size, target_size):\n",
    "\n",
    "        # Initialization of given values\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.target_size = target_size\n",
    "\n",
    "        \n",
    "        # Weights and Bias for input and hidden tensor\n",
    "        self.Wi_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Ui_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bi_l1 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))\n",
    "\n",
    "        \n",
    "        self.Wf_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uf_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bf_l1 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wog_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uog_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bog_l1 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wc_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uc_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bc_l1 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        #Weights for layer 2\n",
    "        self.Wi_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.Ui_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bi_l2 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))\n",
    "\n",
    "        \n",
    "        self.Wf_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.Uf_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bf_l2 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wog_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.Uog_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bog_l2 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wc_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.Uc_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bc_l2 = tf.Variable(tf.truncated_normal([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Weights for output layers\n",
    "        self.Wo = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.target_size],mean=0,stddev=.1))\n",
    "        self.bo = tf.Variable(tf.truncated_normal([self.target_size],mean=0,stddev=.1))\n",
    "\n",
    "        # Placeholder for input vector with shape[batch, seq, embeddings]\n",
    "        self._inputs = tf.placeholder(tf.float32,\n",
    "                                      shape=[None, None, self.input_size],\n",
    "                                      name='inputs')\n",
    "\n",
    "        # Processing inputs to work with scan function\n",
    "        self.processed_input = process_batch_input_for_RNN(self._inputs)\n",
    "\n",
    "        '''\n",
    "        Initial hidden state's shape is [1,self.hidden_layer_size]\n",
    "        In First time stamp, we are doing dot product with weights to\n",
    "        get the shape of [batch_size, self.hidden_layer_size].\n",
    "        For this dot product tensorflow use broadcasting. But during\n",
    "        Back propagation a low level error occurs.\n",
    "        So to solve the problem it was needed to initialize initial\n",
    "        hiddden state of size [batch_size, self.hidden_layer_size].\n",
    "        So here is a little hack !!!! Getting the same shaped\n",
    "        initial hidden state of zeros.\n",
    "        '''\n",
    "\n",
    "        self.initial_hidden = self._inputs[:, 0, :]\n",
    "        self.initial_hidden= tf.matmul(\n",
    "            self.initial_hidden, tf.zeros([input_size, hidden_layer_size]))\n",
    "        \n",
    "        \n",
    "        self.initial_hidden=tf.stack([self.initial_hidden,self.initial_hidden,self.initial_hidden,self.initial_hidden])\n",
    "    # Function for LSTM cell.\n",
    "    def Lstm(self, previous_hidden_memory_tuple, x):\n",
    "        \"\"\"\n",
    "        This function takes previous hidden state and memory tuple with input and\n",
    "        outputs current hidden state.\n",
    "        \"\"\"\n",
    "        \n",
    "        previous_hidden_state_l1,c_prev_l1,previous_hidden_state_l2,c_prev_l2=tf.unstack(previous_hidden_memory_tuple)\n",
    "        \n",
    "        #Input Gate\n",
    "        i_l1= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wi_l1)+tf.matmul(previous_hidden_state_l1,self.Ui_l1) + self.bi_l1 \n",
    "        )\n",
    "        \n",
    "        #Forget Gate\n",
    "        f_l1= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wf_l1)+tf.matmul(previous_hidden_state_l1,self.Uf_l1) + self.bf_l1 \n",
    "        )\n",
    "        \n",
    "        #Output Gate\n",
    "        o_l1= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wog_l1)+tf.matmul(previous_hidden_state_l1,self.Uog_l1) + self.bog_l1\n",
    "        )\n",
    "        \n",
    "        #New Memory Cell\n",
    "        c__l1= tf.nn.tanh(\n",
    "            tf.matmul(x,self.Wc_l1)+tf.matmul(previous_hidden_state_l1,self.Uc_l1) + self.bc_l1 \n",
    "        ) \n",
    "        \n",
    "        #Final Memory cell\n",
    "        c_l1= f_l1*c_prev_l1 + i_l1*c__l1\n",
    "        \n",
    "        #Current Hidden state\n",
    "        current_hidden_state_l1 = o_l1*tf.nn.tanh(c_l1)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Input Gate for layer 2\n",
    "        i_l2= tf.sigmoid(\n",
    "            tf.matmul(current_hidden_state_l1,self.Wi_l2)+tf.matmul(previous_hidden_state_l2,self.Ui_l2) + self.bi_l2 \n",
    "        )\n",
    "        \n",
    "        #Forget Gate for layer 2\n",
    "        f_l2= tf.sigmoid(\n",
    "            tf.matmul(current_hidden_state_l1,self.Wf_l2)+tf.matmul(previous_hidden_state_l2,self.Uf_l2) + self.bf_l2 \n",
    "        )\n",
    "        \n",
    "        #Output Gate for layer 2\n",
    "        o_l2= tf.sigmoid(\n",
    "            tf.matmul(current_hidden_state_l1,self.Wog_l2)+tf.matmul(previous_hidden_state_l2,self.Uog_l2) + self.bog_l2\n",
    "        )\n",
    "        \n",
    "        #New Memory Cell for layer 2\n",
    "        c__l2= tf.nn.tanh(\n",
    "            tf.matmul(current_hidden_state_l1,self.Wc_l2)+tf.matmul(previous_hidden_state_l2,self.Uc_l2) + self.bc_l2\n",
    "        ) \n",
    "        \n",
    "        #Final Memory cell for layer 2\n",
    "        c_l2= f_l2*c_prev_l2 + i_l2*c__l2\n",
    "        \n",
    "        #Current Hidden state\n",
    "        current_hidden_state_l2 = o_l2*tf.nn.tanh(c_l2)        \n",
    "        \n",
    "        \n",
    "\n",
    "        return tf.stack([current_hidden_state_l1,c_l1,current_hidden_state_l2,c_l2])\n",
    "\n",
    "    # Function for getting all hidden state.\n",
    "    def get_states(self):\n",
    "        \"\"\"\n",
    "        Iterates through time/ sequence to get all hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        # Getting all hidden state throuh time\n",
    "        all_hidden_states = tf.scan(self.Lstm,\n",
    "                                    self.processed_input,\n",
    "                                    initializer=self.initial_hidden,\n",
    "                                    name='states')\n",
    "        all_hidden_states=all_hidden_states[:,3,:,:]\n",
    "        \n",
    "        return all_hidden_states\n",
    "\n",
    "    # Function to get output from a hidden layer\n",
    "    def get_output(self, hidden_state):\n",
    "        \"\"\"\n",
    "        This function takes hidden state and returns output\n",
    "        \"\"\"\n",
    "        output = tf.nn.relu(tf.matmul(hidden_state, self.Wo) + self.bo)\n",
    "\n",
    "        return output\n",
    "\n",
    "    # Function for getting all output layers\n",
    "    def get_outputs(self):\n",
    "        \"\"\"\n",
    "        Iterating through hidden states to get outputs for all timestamp\n",
    "        \"\"\"\n",
    "        all_hidden_states = self.get_states()\n",
    "\n",
    "        all_outputs = tf.map_fn(self.get_output, all_hidden_states)\n",
    "\n",
    "        return all_outputs\n",
    "\n",
    "\n",
    "# Function to convert batch input data to use scan ops of tensorflow.\n",
    "def process_batch_input_for_RNN(batch_input):\n",
    "    \"\"\"\n",
    "    Process tensor of size [5,3,2] to [3,5,2]\n",
    "    \"\"\"\n",
    "    batch_input_ = tf.transpose(batch_input, perm=[2, 0, 1])\n",
    "    X = tf.transpose(batch_input_)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Placeholder and initializers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 30\n",
    "input_size = 8\n",
    "target_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, shape=[None, target_size],name='inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Initializing rnn object\n",
    "rnn=LSTM_cell( input_size, hidden_layer_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Getting all outputs from rnn\n",
    "outputs = rnn.get_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Getting final output through indexing after reversing\n",
    "last_output = outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#As rnn model output the final layer through Relu activation softmax is used for final output.\n",
    "output=tf.nn.softmax(last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Computing the Cross Entropy loss \n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Trainning with Adadelta Optimizer\n",
    "train_step = tf.train.AdadeltaOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Calculatio of correct prediction and accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Function to get on hot\n",
    "def get_on_hot(number):\n",
    "    on_hot=[0]*10\n",
    "    on_hot[number]=1\n",
    "    return on_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Using Sklearn MNIST dataset.\n",
    "digits = datasets.load_digits()\n",
    "X=digits.images\n",
    "Y_=digits.target\n",
    "\n",
    "Y=map(get_on_hot,Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Getting Train and test Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.22, random_state=42)\n",
    "\n",
    "#Cuttting for simple iteration\n",
    "X_train=X_train[:1400]\n",
    "y_train=y_train[:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-d5415974c3de>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff85ce1b810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 199 Loss: 234.319 Train Accuracy: 10.3571 Test Accuracy: 13.8889\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff85ce1b810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Iterations to do trainning\n",
    "for epoch in range(200):\n",
    "    \n",
    "    start=0\n",
    "    end=100\n",
    "    for i in range(14):\n",
    "        \n",
    "        X=X_train[start:end]\n",
    "        Y=y_train[start:end]\n",
    "        start=end\n",
    "        end=start+100\n",
    "        sess.run(train_step,feed_dict={rnn._inputs:X, y:Y})\n",
    "    \n",
    "    Loss=str(sess.run(cross_entropy,feed_dict={rnn._inputs:X, y:Y}))\n",
    "    Train_accuracy=str(sess.run(accuracy,feed_dict={rnn._inputs:X_train, y:y_train}))\n",
    "    Test_accuracy=str(sess.run(accuracy,feed_dict={rnn._inputs:X_test, y:y_test}))\n",
    "    \n",
    "\n",
    "    pl.plot([epoch],Loss,'b.',)\n",
    "    pl.plot([epoch],Train_accuracy,'r*',)\n",
    "    pl.plot([epoch],Test_accuracy,'g+')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())   \n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    print(\"\\rIteration: %s Loss: %s Train Accuracy: %s Test Accuracy: %s\"%(epoch,Loss,Train_accuracy,Test_accuracy)),\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
