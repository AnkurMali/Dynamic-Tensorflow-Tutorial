{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <span style=\"color:green\"> Bi-LSTM RNN ON 8*8 MNIST DATASET TO PREDICT TEN CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "### <span style=\"color:blue\">Its a dynamic sequence and batch bi directional LSTM . This is created with tensorflow scan and map higher ops!!!! \n",
    "###  <span style=\"color:blue\">This is a base bi directional LSTM which can be used to create Neural Stack Machine, Neural Turing Machine and  RNN-EM and so on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jli183/tensorflow/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bi-LSTM class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Bi_LSTM_cell(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Bi directional LSTM cell object which takes 3 arguments for initialization.\n",
    "    input_size = Input Vector size\n",
    "    hidden_layer_size = Hidden layer size\n",
    "    target_size = Output vector size\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_size, target_size):\n",
    "\n",
    "        # Initialization of given values\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # Weights and Bias for input and hidden tensor for forward pass\n",
    "        self.Wi = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Ui = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bi = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        \n",
    "        self.Wf = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uf = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bf = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wog = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uog = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bog = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wc = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uc = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bc = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "\n",
    "        \n",
    "        \n",
    "        # Weights and Bias for input and hidden tensor for backward pass\n",
    "        self.Wi1 = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Ui1 = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bi1 = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        \n",
    "        self.Wf1 = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uf1 = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bf1 = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wog1 = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uog1 = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bog1 = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wc1 = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uc1 = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bc1 = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Weights for output layers\n",
    "        self.Wo = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size*2, self.target_size],mean=0,stddev=.01))\n",
    "        self.bo = tf.Variable(tf.truncated_normal([self.target_size],mean=0,stddev=.01))\n",
    "\n",
    "        # Placeholder for input vector with shape[batch, seq, embeddings]\n",
    "        self._inputs = tf.placeholder(tf.float32,\n",
    "                                      shape=[None, None, self.input_size],\n",
    "                                      name='inputs')\n",
    "        \n",
    "        #Reversing the inputs by sequence for backward pass of the LSTM\n",
    "        self._inputs_rev= tf.reverse(self._inputs,[False,True,False])\n",
    "        \n",
    "        # Processing inputs to work with scan function\n",
    "        self.processed_input = process_batch_input_for_RNN(self._inputs)\n",
    "        \n",
    "        #For bacward pass of the LSTM\n",
    "        self.processed_input_rev = process_batch_input_for_RNN(self._inputs_rev)\n",
    "        \n",
    "        '''\n",
    "        Initial hidden state's shape is [1,self.hidden_layer_size]\n",
    "        In First time stamp, we are doing dot product with weights to\n",
    "        get the shape of [batch_size, self.hidden_layer_size].\n",
    "        For this dot product tensorflow use broadcasting. But during\n",
    "        Back propagation a low level error occurs.\n",
    "        So to solve the problem it was needed to initialize initial\n",
    "        hiddden state of size [batch_size, self.hidden_layer_size].\n",
    "        So here is a little hack !!!! Getting the same shaped\n",
    "        initial hidden state of zeros.\n",
    "        '''\n",
    "\n",
    "        self.initial_hidden = self._inputs[:, 0, :]\n",
    "        self.initial_hidden= tf.matmul(\n",
    "            self.initial_hidden, tf.zeros([input_size, hidden_layer_size]))\n",
    "        \n",
    "        \n",
    "        self.initial_hidden=tf.stack([self.initial_hidden,self.initial_hidden])\n",
    "        \n",
    "    # Function for Forward LSTM cell. \n",
    "    def Lstm_f(self, previous_hidden_memory_tuple, x):\n",
    "        \"\"\"\n",
    "        This function takes previous hidden state and memory tuple with input and\n",
    "        outputs current hidden state.\n",
    "        \"\"\"\n",
    "        \n",
    "        previous_hidden_state,c_prev=tf.unstack(previous_hidden_memory_tuple)\n",
    "        \n",
    "        #Input Gate\n",
    "        i= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wi)+tf.matmul(previous_hidden_state,self.Ui) + self.bi \n",
    "        )\n",
    "        \n",
    "        #Forget Gate\n",
    "        f= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wf)+tf.matmul(previous_hidden_state,self.Uf) + self.bf \n",
    "        )\n",
    "        \n",
    "        #Output Gate\n",
    "        o= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wog)+tf.matmul(previous_hidden_state,self.Uog) + self.bog\n",
    "        )\n",
    "        \n",
    "        #New Memory Cell\n",
    "        c_= tf.nn.tanh(\n",
    "            tf.matmul(x,self.Wc)+tf.matmul(previous_hidden_state,self.Uc) + self.bc \n",
    "        ) \n",
    "        \n",
    "        #Final Memory cell\n",
    "        c= f*c_prev + i*c_\n",
    "        \n",
    "        #Current Hidden state\n",
    "        current_hidden_state = o*tf.nn.tanh(c)\n",
    "\n",
    "\n",
    "        return tf.stack([current_hidden_state,c])\n",
    "\n",
    "    # Function for Forward LSTM cell. \n",
    "    def Lstm_b(self, previous_hidden_memory_tuple, x):\n",
    "        \"\"\"\n",
    "        This function takes previous hidden state and memory tuple with input and\n",
    "        outputs current hidden state.\n",
    "        \"\"\"\n",
    "        \n",
    "        previous_hidden_state,c_prev=tf.unstack(previous_hidden_memory_tuple)\n",
    "        \n",
    "        #Input Gate\n",
    "        i= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wi1)+tf.matmul(previous_hidden_state,self.Ui1) + self.bi1\n",
    "        )\n",
    "        \n",
    "        #Forget Gate\n",
    "        f= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wf1)+tf.matmul(previous_hidden_state,self.Uf1) + self.bf1 \n",
    "        )\n",
    "        \n",
    "        #Output Gate\n",
    "        o= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wog1)+tf.matmul(previous_hidden_state,self.Uog1) + self.bog1\n",
    "        )\n",
    "        \n",
    "        #New Memory Cell\n",
    "        c_= tf.nn.tanh(\n",
    "            tf.matmul(x,self.Wc1)+tf.matmul(previous_hidden_state,self.Uc1) + self.bc1 \n",
    "        ) \n",
    "        \n",
    "        #Final Memory cell\n",
    "        c= f*c_prev + i*c_\n",
    "        \n",
    "        #Current Hidden state\n",
    "        current_hidden_state = o*tf.nn.tanh(c)\n",
    "\n",
    "\n",
    "        return tf.stack([current_hidden_state,c])    \n",
    "    \n",
    "    \n",
    "\n",
    "    #Function to get the hidden and memory cells after forward pass\n",
    "    def get_states_f(self):\n",
    "        \"\"\"\n",
    "        Iterates through time/ sequence to get all hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        # Getting all hidden state throuh time\n",
    "        all_hidden_memory_states = tf.scan(self.Lstm_f,\n",
    "                                    self.processed_input,\n",
    "                                    initializer=self.initial_hidden,\n",
    "                                    name='states')\n",
    "        \n",
    "        all_hidden_states=all_hidden_memory_states[:,0,:,:]\n",
    "        all_memory_states=all_hidden_memory_states[:,1,:,:]\n",
    "\n",
    "        \n",
    "        return all_hidden_states,all_memory_states\n",
    "\n",
    "    \n",
    "    #Function to get the hidden and memory cells after backward pass\n",
    "    def get_states_b(self):\n",
    "        \"\"\"\n",
    "        Iterates through time/ sequence to get all hidden state\n",
    "        \"\"\"\n",
    "        \n",
    "        all_hidden_states, all_memory_states = self.get_states_f()\n",
    "        \n",
    "        #Reversing the hidden and memory state to get the final hidden and memory state\n",
    "        last_hidden_states = all_hidden_states[-1]\n",
    "        last_memory_states = all_memory_states[-1]\n",
    "        \n",
    "        #For backward pass using the last hidden and memory of the forward pass\n",
    "        initial_hidden=tf.stack([last_hidden_states,last_memory_states])\n",
    "        \n",
    "        # Getting all hidden state throuh time\n",
    "        all_hidden_memory_states = tf.scan(self.Lstm_b,\n",
    "                                    self.processed_input_rev,\n",
    "                                    initializer=initial_hidden,\n",
    "                                    name='states')\n",
    "        \n",
    "        #Now reversing the states to keep those in original order\n",
    "        #all_hidden_states=tf.reverse(all_hidden_memory_states[:,0,:,:],[True,False,False])\n",
    "        #all_memory_states=tf.reverse(all_hidden_memory_states[:,1,:,:],[True,False,False])\n",
    "\n",
    "        \n",
    "        return all_hidden_states,all_memory_states    \n",
    "    \n",
    "    \n",
    "    #Function to concat the hiddenstates for backward and forward pass\n",
    "    def get_concat_hidden(self):\n",
    "        \n",
    "        #Getting hidden and memory for the forward pass\n",
    "        all_hidden_states_f, all_memory_states_f = self.get_states_f()\n",
    "        \n",
    "        #Getting hidden and memory for the backward pass\n",
    "        all_hidden_states_b, all_memory_states_b = self.get_states_b()\n",
    "        \n",
    "        #Concating the hidden states of forward and backward pass\n",
    "        concat_hidden=tf.concat([all_hidden_states_f,all_hidden_states_b],2)\n",
    "        \n",
    "        return concat_hidden\n",
    "\n",
    "\n",
    "    # Function to get output from a hidden layer\n",
    "    def get_output(self, hidden_state):\n",
    "        \"\"\"\n",
    "        This function takes hidden state and returns output\n",
    "        \"\"\"\n",
    "        #output = tf.nn.sigmoid(tf.matmul(hidden_state, self.Wo) + self.bo)\n",
    "        output = tf.nn.sigmoid(tf.matmul(hidden_state, self.Wo) + self.bo)\n",
    "        return output\n",
    "\n",
    "    # Function for getting all output layers\n",
    "    def get_outputs(self):\n",
    "        \"\"\"\n",
    "        Iterating through hidden states to get outputs for all timestamp\n",
    "        \"\"\"\n",
    "        all_hidden_states = self.get_concat_hidden()\n",
    "\n",
    "        all_outputs = tf.map_fn(self.get_output, all_hidden_states)\n",
    "\n",
    "        return all_outputs\n",
    "\n",
    "\n",
    "# Function to convert batch input data to use scan ops of tensorflow.\n",
    "def process_batch_input_for_RNN(batch_input):\n",
    "    \"\"\"\n",
    "    Process tensor of size [5,3,2] to [3,5,2]\n",
    "    \"\"\"\n",
    "    batch_input_ = tf.transpose(batch_input, perm=[2, 0, 1])\n",
    "    X = tf.transpose(batch_input_)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Placeholder and initializers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 30\n",
    "input_size = 8\n",
    "target_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, shape=[None, target_size],name='inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Initializing rnn object\n",
    "rnn=Bi_LSTM_cell( input_size, hidden_layer_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Getting all outputs from rnn\n",
    "outputs = rnn.get_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Getting first output through indexing\n",
    "last_output = outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#As rnn model output the final layer through Relu activation softmax is used for final output.\n",
    "output=tf.nn.softmax(last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Computing the Cross Entropy loss \n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Trainning with Adadelta Optimizer\n",
    "train_step = tf.train.AdadeltaOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Calculatio of correct prediction and accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Function to get on hot\n",
    "def get_on_hot(number):\n",
    "    on_hot=[0]*10\n",
    "    on_hot[number]=1\n",
    "    return on_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Using Sklearn MNIST dataset.\n",
    "digits = datasets.load_digits()\n",
    "X=digits.images\n",
    "Y_=digits.target\n",
    "\n",
    "Y=map(get_on_hot,Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Getting Train and test Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.22, random_state=42)\n",
    "\n",
    "#Cuttting for simple iteration\n",
    "X_train=X_train[:1400]\n",
    "y_train=y_train[:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-d5415974c3de>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npMb9PyxYaotUsfGmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c19771510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 199 Loss: 230.236 Train Accuracy: 11.8 Test Accuracy: 9.84848\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD4lJREFUeJzt3WusXFd5xvH/YzsxiEubYNdYudSO5CI5lZrAUYRVIK5S\nkRC1OGmlyBRVrhrJLUoRqK2qpEi1+RAJWkE/FZAREaYKhFQQxR/oJVgEVCklHAcH7IQ0JhfFlm+Y\nSkECAnbefphtmBif65yZOWf5/5NGs2bN3vO+WbPznDn7zIxTVUiS2rVs3A1IkobLoJekxhn0ktQ4\ng16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bsW4GwBYtWpVrVu3btxtSNKSsm/fvh9U1eqZtlsU\nQb9u3TomJyfH3YYkLSlJnp/Ndp66kaTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY1bFG+vHMQjj8Dn\nPtcbX3stfPvbCz8+dQre8IbhPLZ1rGOdC7vOqVOweTNs2sTQLOmgf+SR3gL97GfDrZPAKP7FRetY\nxzoXXp1ly2DlSti7d3hhv6RP3Tz8MPz858OvM6p/Vtc61rHOhVfn5Zd7L1YffnhhH7ffkg76zZvh\noouGXycZfg3rWMc6F2adZcvg4ot7eTYsS/rUzaZNvZ+CnqO3jnWss1TreI5+FjZtGu4CSdJSt6RP\n3UiSZmbQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPo\nJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY2bMeiTXJHka0meSHIwyQe6+UuTPJTk\n6e76kr597kpyKMlTSW4c5n+AJGl6s3lFfxr4m6raCLwVuCPJRuBOYG9VbQD2drfp7tsKXA3cBHwi\nyfJhNC9JmtmMQV9VR6vqsW78I+BJ4DJgC7C722w3cEs33gLcV1UvVdWzwCHguoVuXJI0O3M6R59k\nHXAt8E1gTVUd7e46BqzpxpcBL/TtdribO/extieZTDJ58uTJObYtSZqtWQd9ktcCXwI+WFUv9t9X\nVQXUXApX1a6qmqiqidWrV89lV0nSHMwq6JNcRC/k762qL3fTx5Os7e5fC5zo5o8AV/Ttfnk3J0ka\ng9m86ybAZ4Anq+rjfXftAbZ1423Ag33zW5OsTLIe2AA8unAtS5LmYsUstvld4E+B7ybZ3839PfAR\n4P4ktwPPA7cBVNXBJPcDT9B7x84dVXVmwTuXJM3KjEFfVf8NZIq7b5hin7uBuwfoS5K0QPxkrCQ1\nzqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMM\neklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCX\npMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaN2PQJ7knyYkk\nB/rmdiY5kmR/d7m57767khxK8lSSG4fVuCRpdmbziv6zwE3nmf/nqrqmu3wFIMlGYCtwdbfPJ5Is\nX6hmJUlzN2PQV9U3gB/O8vG2APdV1UtV9SxwCLhugP4kSQMa5Bz9+5N8pzu1c0k3dxnwQt82h7u5\nX5Fke5LJJJMnT54coA1J0nTmG/SfBK4CrgGOAh+b6wNU1a6qmqiqidWrV8+zDUnSTOYV9FV1vKrO\nVNXLwKf55emZI8AVfZte3s1JksZkXkGfZG3fzVuBs+/I2QNsTbIyyXpgA/DoYC1KkgaxYqYNknwB\n2AysSnIY2AFsTnINUMBzwF8AVNXBJPcDTwCngTuq6sxwWpckzUaqatw9MDExUZOTk+NuQ5KWlCT7\nqmpipu38ZKwkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4\ng16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPo\nJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4GYM+\nyT1JTiQ50Dd3aZKHkjzdXV/Sd99dSQ4leSrJjcNqXJI0O7N5Rf9Z4KZz5u4E9lbVBmBvd5skG4Gt\nwNXdPp9IsnzBupUkzdmMQV9V3wB+eM70FmB3N94N3NI3f19VvVRVzwKHgOsWqFdJ0jzM9xz9mqo6\n2o2PAWu68WXAC33bHe7mJEljMvAfY6uqgJrrfkm2J5lMMnny5MlB25AkTWG+QX88yVqA7vpEN38E\nuKJvu8u7uV9RVbuqaqKqJlavXj3PNiRJM5lv0O8BtnXjbcCDffNbk6xMsh7YADw6WIuSpEGsmGmD\nJF8ANgOrkhwGdgAfAe5PcjvwPHAbQFUdTHI/8ARwGrijqs4MqXdJ0izMGPRV9Z4p7rphiu3vBu4e\npClJ0sLxk7GS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Lj\nDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6g\nl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJ\natyKQXZO8hzwI+AMcLqqJpJcCnwRWAc8B9xWVf83WJuSpPlaiFf0v1dV11TVRHf7TmBvVW0A9na3\nJUljMoxTN1uA3d14N3DLEGpIkmZp0KAv4KtJ9iXZ3s2tqaqj3fgYsGbAGpKkAQx0jh54W1UdSfIb\nwENJvtd/Z1VVkjrfjt0Phu0AV1555YBtSJKmMtAr+qo60l2fAB4ArgOOJ1kL0F2fmGLfXVU1UVUT\nq1evHqQNSdI05h30SV6T5HVnx8A7gQPAHmBbt9k24MFBm5Qkzd8gp27WAA8kOfs4n6+q/0jyLeD+\nJLcDzwO3Dd6mJGm+5h30VfUM8DvnmT8F3DBIU5KkheMnYyWpcQa9JDXOoJekxhn0ktQ4g16SGmfQ\nS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0k\nNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDVu6Qf90aPw1rfCpk3w+OPDGV9/\n/fAe2zrWsc6FXef66+HYseHmZFWN/fKWt7yl5u1976uC3uXqq4czXrZseI9tHetY58Kus2xZL8fm\nAZicTcamt+14TUxM1OTk5Nx2evWr4ac/HU5DkjQiOzfDzoe7G696FfzkJ7PeN8m+qpqYabule+rm\nmWfg1lth+XJ+vBy+9Kbe9EKO7/3t3ngYj20d61jnwq5z9vE+vJneC9f3vheefZZhWDGURx2FtWth\nzRo4c4aVgROv7U2vfHnhxi+u7I2H8djWsY51Luw6Zx8PgJdegte/Ht74RoZhyZ662fnwTj789Q8P\nqSNJGr0d1+9g5+ads96++VM3OzfvpHYUteOXP6iGObaOdaxjnWHVOZtlcwn5uViyQS9Jmp2le46+\nz47rd4xkbB3rWMc6w6wzLEv2HL0kXejGfo4+yU1JnkpyKMmdw6ojSZreUII+yXLgX4B3ARuB9yTZ\nOIxakqTpDesV/XXAoap6pqp+BtwHbBlSLUnSNIYV9JcBL/TdPtzNSZJGbGxvr0yyPclkksmTJ0+O\nqw1Jat6w3l55BLii7/bl3dwvVNUuYBdAkpNJnh+g3irgBwPsPyz2NTf2NXeLtTf7mpv59vWbs9lo\nKG+vTLIC+F/gBnoB/y3gT6rq4IIX69WbnM1bjEbNvubGvuZusfZmX3Mz7L6G8oq+qk4n+SvgP4Hl\nwD3DCnlJ0vSG9snYqvoK8JVhPb4kaXZa+a6bXeNuYAr2NTf2NXeLtTf7mpuh9rUovgJBkjQ8rbyi\nlyRNYUkH/WL5Pp0kVyT5WpInkhxM8oFufmeSI0n2d5ebx9Dbc0m+29Wf7OYuTfJQkqe760vG0Neb\n+tZlf5IXk3xwHGuW5J4kJ5Ic6Jubco2S3NUdc08luXHEff1Tku8l+U6SB5L8eje/LslP+tbtU8Pq\na5repnzuxrxmX+zr6bkk+7v5ka3ZNBkxmuNsNv+C+GK80Hs3z/eBq4CLgceBjWPqZS3w5m78Onpv\nLd0I7AT+dszr9Byw6py5fwTu7MZ3Ah9dBM/lMXrvCR75mgHvAN4MHJhpjbrn9XFgJbC+OwaXj7Cv\ndwIruvFH+/pa17/dmNbsvM/duNfsnPs/BvzDqNdsmowYyXG2lF/RL5rv06mqo1X1WDf+EfAki/sr\nH7YAu7vxbuCWMfYCvc9bfL+qBvnQ3LxV1TeAH54zPdUabQHuq6qXqupZ4BC9Y3EkfVXVf1XV6e7m\n/9D7MOLITbFmUxnrmp2VJMBtwBeGUXs602TESI6zpRz0i/L7dJKsA64FvtlNvb/7NfuecZwiAQr4\napJ9SbZ3c2uq6mg3PgasGUNf/bbyyv/5xr1mMPUaLabj7s+Bf++7vb47BfH1JG8fU0/ne+4Wy5q9\nHTheVU/3zY18zc7JiJEcZ0s56BedJK8FvgR8sKpeBD5J79TSNcBRer82jtrbquoael8ZfUeSd/Tf\nWb3fE8f21qskFwPvBv6tm1oMa/YK416j80nyIeA0cG83dRS4snuu/xr4fJLXj7itRffcneM9vPIF\nxcjX7DwZ8QvDPM6WctDP+H06o5TkInpP4L1V9WWAqjpeVWeq6mXg0wzp19XpVNWR7voE8EDXw/Ek\na7u+1wInRt1Xn3cBj1XVcVgca9aZao3Gftwl+TPgD4D3duFA9yv+qW68j9453d8aZV/TPHeLYc1W\nAH8EfPHs3KjX7HwZwYiOs6Uc9N8CNiRZ370q3ArsGUcj3bm/zwBPVtXH++bX9m12K3Dg3H2H3Ndr\nkrzu7JjeH/IO0Funbd1m24AHR9nXOV7xKmvca9ZnqjXaA2xNsjLJemAD8OiomkpyE/B3wLur6sd9\n86vT+wd/SHJV19czo+qrqzvVczfWNev8PvC9qjp8dmKUazZVRjCq42wUf3Ee4l+yb6b31+vvAx8a\nYx9vo/cr13eA/d3lZuBfge9283uAtSPu6yp6f7l/HDh4do2ANwB7gaeBrwKXjmndXgOcAn6tb27k\na0bvB81R4Of0zoXePt0aAR/qjrmngHeNuK9D9M7dnj3OPtVt+8fdc7wfeAz4wzGs2ZTP3TjXrJv/\nLPCX52w7sjWbJiNGcpz5yVhJatxSPnUjSZoFg16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCX\npMb9PyxYaotUsfGmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c19771510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Iterations to do trainning\n",
    "for epoch in range(200):\n",
    "    \n",
    "    start=0\n",
    "    end=100\n",
    "    for i in range(14):\n",
    "        \n",
    "        X=X_train[start:end]\n",
    "        Y=y_train[start:end]\n",
    "        start=end\n",
    "        end=start+100\n",
    "        sess.run(train_step,feed_dict={rnn._inputs:X, y:Y})\n",
    "    \n",
    "    Loss=str(sess.run(cross_entropy,feed_dict={rnn._inputs:X, y:Y}))\n",
    "    Train_accuracy=str(sess.run(accuracy,feed_dict={rnn._inputs:X_train[:500], y:y_train[:500]}))\n",
    "    Test_accuracy=str(sess.run(accuracy,feed_dict={rnn._inputs:X_test, y:y_test}))\n",
    "    \n",
    "\n",
    "    pl.plot([epoch],Loss,'b.',)\n",
    "    pl.plot([epoch],Train_accuracy,'r*',)\n",
    "    pl.plot([epoch],Test_accuracy,'g+')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())   \n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    print(\"\\rIteration: %s Loss: %s Train Accuracy: %s Test Accuracy: %s\"%(epoch,Loss,Train_accuracy,Test_accuracy)),\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
